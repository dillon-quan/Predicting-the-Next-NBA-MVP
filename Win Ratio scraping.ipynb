{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Basketball Reference for each team Win Lose Ratio from 2000 to 2018 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three cells setup the get request of the url and save the response to the variable r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#send a get request with the specified url and return the response to the store variable to retrieve the text. Then used\n",
    "#Beautiful Soup library is a parser that allows me to parse through the html code from the get response.\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2018.html'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To scrape the column headers from the html, I used the find_all method from the soup library to find the corresponding \n",
    "#hmtl tags that the information I need is under. I then use the getText method to retrieve the texts within these tags.\n",
    "\n",
    "columns = []\n",
    "\n",
    "for i in range(8):\n",
    "    header = soup.find_all('tr', limit = 2)[1].find_all('th')[i].getText()\n",
    "    columns.append(header)\n",
    "\n",
    "columns[0] = 'Team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here I am scraping off the data from each team in the webpage as a list and appending the list in a list called Teams_season.\n",
    "\n",
    "Teams_Season = []\n",
    "size_data_rows = len(soup.find_all('tr', limit = 35))\n",
    "\n",
    "for i in range(2,size_data_rows):\n",
    "    data_rows = soup.find_all('tr', limit = 35)[i]\n",
    "    try:\n",
    "        team = [stat.getText() for stat in data_rows if 'Division' not in stat.getText()]\n",
    "        Teams_Season.append(team)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Teams_Season, columns = columns)\n",
    "df['Year'] = '2018'\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This dictionary was created so that the full name of each team matches the acronym since the info scraped from \n",
    "#the webpage are in full name while the season_stat dataset from kaggle use team acronyms.\n",
    "\n",
    "team_name_acr = {'Boston Celtics': 'BOS', 'New York Knicks':'NYK', 'Philadelphia 76ers':'PHI','Toronto Raptors':'TOR','New Jersey Nets':'NJN', \n",
    "'Chicago Bulls':'CHI', 'Indiana Pacers':'IND', 'Milwaukee Bucks':'MIL', 'Detroit Pistons':'DET','Cleveland Cavaliers':'CLE', \n",
    "'Miami Heat':'MIA', 'Atlanta Hawks':'ATL', 'Orlando Magic':'ORL', 'Washington Wizards':'WAS','Charlotte Bobcats':'CHA',\n",
    "'Oklahoma City Thunder':'OKC', 'Denver Nuggets':'DEN', 'Utah Jazz':'UTA', 'Portland Trail Blazers':'POR',\n",
    "'Minnesota Timberwolves':'MIN','Los Angeles Lakers':'LAL', 'Los Angeles Clippers':'LAC', 'Phoenix Suns':'PHO', 'Golden State Warriors':'GSW',\n",
    "'Sacramento Kings':'SAC','San Antonio Spurs':'SAS', 'Memphis Grizzlies':'MEM', 'Dallas Mavericks':'DAL', 'Houston Rockets':'HOU',\n",
    "'New Orleans Hornets':'NOH', 'New Orleans Pelicans':'NOP', 'Charlotte Hornets':'CHA', 'Vancouver Grizzlies':'VAN', 'Seattle Supersonics': 'SEA', 'Brooklyn Nets': 'BKN'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This nested for loop uses the dictionary to change the team names to its acronyms so that this data can be merged later.\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    for key, value in team_name_acr.items():\n",
    "        try:\n",
    "            if key in df.loc[i, 'Team']:\n",
    "                df.loc[i,'Team'] = value\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Opening a csv file and append data scraped into the file. The cell below shows the dataframe being exported to csv.\n",
    "\n",
    "with open('2018_win_ratio.csv', 'w') as f:\n",
    "    df.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
